找了另外一个项目模仿，然后融合了在第一个项目中用的一些方法  
优化器换成了Adam，调度器重新看了一下余弦退火，然后重构了创建模型和训练模式的代码，确保用了step更新参数  
数据增强和dropout的参数调小了一些，因为在原参数200个周期下，模型训练前期有十几的剧烈波动  
单独分出来了一个不重不漏的验证集，以防测试集污染。  
之前的版本因为只有.pth保存了参数优化器等信息，而找不到模型结构，恢复不出来当时的样子，可能是在无意中把测试集也喂进去了，但是现在无从考证  
重构的epoch下有训练模式和验证模式，以周期为单位，训练全跑完才开始跑验证，这就是为什么周期内部只输出了训练损失而不是二者同时输出，考虑到模式之间切换要占用cpu就不改成原来那样了  
增加模型保存策略，只有在验证损失新低的时候才保存  
当所有epoch跑完之后再用测试集测试  


目前比较纳闷的点：  
1.原来的复现不出来，不知道为什么损失下不去  
2.cpu和gpu占用大幅下降，考虑可能是上面提到的训练和测试之间切换会给cpu上压力  
3.验证损失低于训练损失，考虑可能是训练没有经过数据增强，图案没那么抽象  
4.原来的batch_size用32就内存占用很高了，现在128都可以接受，而且没有出现cpu二三十而gpu99的情况  
5.损失下降有波动，调小数据增强参数以后波动变小但仍然存在，原来准确率可能一下跳十几，现在个位数，但是总体上是平稳下降的，就是慢了点  
6.一直到最后损失都没有稳定在某个值附近，虽然下降变慢但还在下降，epoch二百以上太费时间了就没测，考虑可能是余弦退火的学习率对于全部二百个周期都是平滑下降的  


跑的几个版本大概数据：  
epoch 损失 准确率 时间  
10         87  
20 0.2299 91.62 19min  
100 0.2040 92.88 1h39min  
200 0.1869 93.19 3h25min  
以上几个版本的截图也一并上传了，格式不同是因为微调了日志输出，数据增强参数有小的调整，模型结构没有变化，应该可以认为是同一个模型的多次结果  